---
title: "Maxi"
author: "Claudia Falsetti"
date: "17 February 2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.



** Data Analysis **

Firstly, I set the working directory to point at the folder in which I saved the results.csv files and load the libraries that will be needed throughout the code. 

```{r libraries, warning=FALSE}

library(tidyverse)
library(lme4)
library(scales)

```

Now the .csv files are loaded in as a list and imported within the same dataframe named data_frame. 

```{r dataframe, warning=FALSE, error=FALSE}

results = list.files(pattern = ".csv")
data = lapply(results, read.csv, header = FALSE, stringsAsFactors = FALSE)
data_frame <- do.call("rbind", data)

```


**Data preprocessing**

I eliminated unneeded columnes and rows and prepared the data for descriptive investigation and statistical analysis 

```{r preprocessing }


###Gender <- data_frame[-1: -2, ] %>%
 # select(V30, V33) %>%
  #filter(V30 == 2)

####Nationality <- data_frame[-1: -2, ] %>%
 # select(V30, V33) %>%
  # filter(V30 == 3)

## data_frame$V33 <- as.numeric(data_frame$V33)

## Age <- data_frame[-1: -2, ] %>%
  ## select(V30, V33) %>%
  ## filter(V30 == 1) %>%
  ## summarise(mean_age = mean(V33), SD = sd(V33))


data_frame <- data_frame[-1: -2, ] %>%  ## remove first 2 rows (completion code) 
  dplyr::select(V2, V7, V27, V28, V29, V33, V34)  ## and select relevant columns

colnames(data_frame) <- data_frame[1,]   ####### set the first row to be the header of the data frame 
final_data <- data_frame[-1, ] 

final_data <- filter(final_data, trialNo != "na", trialNo != "", trialNo != "trialNo") 

final_data <- final_data %>%  # add a column for sujb_id, 275 represents n° of trials per participant
  mutate("subj_id" = rep(1:55,each=275))   ### change 48 with actual number of participants

```


**Descriptives.**

Before proceding to the analysis, the dataset is explored. 
This includes measures of means, standard deviations and plots. A new dataframe called Ultimatum is created. It only includes results relative to the ultimatum game. 
The response to the ultimatum game is recoded as accepted = 1, rejected = 0. 
The descriptive statistics for the ultimatum game are summarised in the data_frame called ultim_summary and are visualised with a bar plot. The offers are coded as: 

 - 1: 90/10
 - 2: 75/25
 - 3: 60/40

```{r Descriptive, warning=FALSE}

ultimatum <- final_data %>%   ## create a dataframe with only UltimatumGame results 
  group_by(subj_id) %>%   #### recode response as acceptance -> accepted=1, rejected = 0
    filter(game == "ultimatum") %>% 
      dplyr::mutate(acceptance = if_else(response == 1, 0L, 1L)) %>% 
          dplyr::select(subj_id, everything()) 

####### boxplot 

box_summary <- ultimatum %>%
  group_by(stim_type, subj_id, offer) %>%
  dplyr::summarise(p = mean(acceptance))

box_summary$offer <- as.factor(box_summary$offer)
box_summary$stim_type <- as.factor(box_summary$stim_type)


ggplot(box_summary, aes(x=stim_type, y=p)) + geom_boxplot() + facet_grid(~offer)## boxplot to look at individual variance 

###################

ultim_summary <- ultimatum %>%    #### descriptive statistics 
  group_by(stim_type, offer) %>%
  dplyr::summarise(p = mean(acceptance)) 
  

accepted_only <- ultimatum %>%
  filter(acceptance == 1) %>%
    group_by(offer) %>%
      count(acceptance) %>%
        mutate(perc = n/4125*100) ## 4050 = NUMBER OF TRIALS PER PARTICIPANT BY OFFER = 75 * 54

accepted_only_2 <- ultimatum %>%
filter(acceptance == 1) %>%
group_by(offer, stim_type) %>%
dplyr::count(acceptance)


united <- full_join(accepted_only, accepted_only_2, by = "offer") %>%
  dplyr::select(offer, stim_type, n.x, perc, n.y) %>%
    group_by(offer, stim_type)

acceptance_rates <- vector("numeric", length = length(united$n.y))

for (i in 1:length(united$n.y)) {
    count <- (united[i, "n.y"])
    tot <- (united [i, "n.x"])
    
    
    acceptance_rates[i] <- count/tot*100
      
    }

rates <- do.call(rbind.data.frame, acceptance_rates)
colnames(rates) <- "acceptance_rates"

united["acceptance_rates"] <- rates$acceptance_rates


acceptance_overall <- ggplot(accepted_only, aes(x = offer, y = perc, fill = offer)) + geom_col() + coord_cartesian(ylim = c(0,100)) ## acceptane by offer only 
                                                            

offer_types <- c(
                    `1` = "£10",
                    `2` = "£25",
                    `3` = "£40"
                            )


col_plot <- ggplot(ultim_summary, aes(x = stim_type, y = p, fill = stim_type)) + geom_col() +   facet_grid(~offer, labeller = as_labeller(offer_types)) + labs(fill = "Proposer Type", x = NULL, y = "Proportion of Accepted Offers", title = "Proportion of Accepted Offers by Offer Type and Proposer Type", subtitle = "Offer Amount", caption = "Data from the Ultimatum Game") + scale_y_continuous(labels = percent) 

print(col_plot)

## Summarizes data.
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

summed <- summarySE(ultimatum, measurevar =  "acceptance", groupvars = c("offer", "stim_type"))

ggplot(summed, aes(x = stim_type, y = acceptance, fill = stim_type)) + geom_col() +   facet_grid(~offer, labeller = as_labeller(offer_types)) + labs(fill = "Proposer Type", x = NULL, y = "Proportion of Accepted Offers", title = "Proportion of Accepted Offers by Offer Type and Proposer Type", subtitle = "Offer Amount", caption = "Data from the Ultimatum Game") +  scale_y_continuous(labels = percent) + geom_errorbar(aes(ymin=acceptance-se, ymax=acceptance+se), width=.1)

#### try white background 


```

Preparing the data for the analysis : **recoding** .

Due to the binary nature of the dependent variable and its binomial distribution, a mixed effects model was used to analyse the data. In the model, the acceptance to the ultimatum game was the response variable and offer and stimulus type were the predictors. 


```{r statistical analysis - regression, warning= FALSE, results="hide"  }

###### re- coding 

ultimatum_dev <- ultimatum %>%
  mutate(offer_1 = ifelse(offer == "1", .5, -.5),
    offer_2 = ifelse(offer == "2", .5, -.5),
      brand = ifelse(stim_type == "brand", .5, -.5),
        human = ifelse(stim_type == "human", .5, -5))

model <- glmer(acceptance ~ (offer_1 + offer_2) * (brand + human) + ( (offer_1 + offer_2) * (brand + human)||subj_id) + ((offer_1 + offer_2) * (brand + human) || stim1), ultimatum_dev, binomial, control=glmerControl(optimizer="bobyqa", optCtrl= list(maxfun=100000)))

ultimatum$stim_type <- as.factor(ultimatum$stim_type)
ultimatum$offer <- as.factor(ultimatum$offer)
ultimatum$subj_id <- as.factor(ultimatum$subj_id)

model2 <- glmer(acceptance ~ (offer_1 + offer_2) * (brand + human) + ( (offer_1 + offer_2) * (brand + human)||subj_id), ultimatum_dev, binomial, control=glmerControl(optimizer="bobyqa", optCtrl= list(maxfun=100000)))

summary(model2)


#predict gives the predicted value in terms of logits


  plot.dat <- data.frame(prob = ult_dev_2$prob,
                       offer = ult_dev_2$offer,
                       fit = predict(model2, ult_dev_2))
#convert those logit values to probabilities
plot.dat$fit_prob <- exp(plot.dat$fit)/(1+exp(plot.dat$fit))

library(ggplot2)
ggplot(plot.dat, aes(x=age, y=prob)) + 
  geom_point() +
  geom_line(aes(x=age, y=fit_prob))

######################
library(emmeans)
####### to test contrastst

mod_paired <- emtrends(model_code, "offer_1", var = "brand")
mod_paired
pairs(mod_paired)


qqnorm(resid(model2))
hist(resid(model2))
plot(fitted(model_code), resid(model_code)) # residuals vs fitted 




install.packages("blmeco")
library(blmeco)

dispersion_glmer(model_code)


#get confidence intervals 

se <- sqrt(diag(vcov(model2)))
(tab <- cbind(Est = fixef(model2), LL = fixef(model2) - 1.96 * se, UL = fixef(model2) + 1.96*se))


se <- sqrt(diag(vcov(model_code)))
(tab <- cbind(Est = fixef(model_code), LL = fixef(model_code) - 1.96 * se, UL = fixef(model_code) + 1.96*se))


## to get odds ratios instead of coefficients on the logit scale, exponentiate the estimates and CIs 


# The predicted value for this condition: the intercept, plus the dummy coefficient for this condition
offer1_value <- (fixef(model_code)["(Intercept)"]) + (fixef(model_code)["offer_1"])
offer1_value
# Converting the predicted value from log odds into percentage
exp( offer1_value ) / ( 1 + exp( offer1_value ) )


exp(tab)


sjPlot::sjp.glmer(model2, type = "fe.pc")


summary(model2)

##likelihood ratio tests 

mod2 <- update(model2, . ~ . -offer_1 -offer_2)
summary(mod2)
anova(model2, mod2) # test main effect of type of offer

mod3 <- update(model2, . ~ . -brand - human)
summary(mod3)
anova(model2, mod3) # test main effect of source (stim_type)

mod4 <- update(model2, . ~ . -offer_1:brand - offer_1:human - offer_2:brand - offer_2:human)
anova(model2, mod4) # test interaction



```



As expected, there was a main effect of offer type such that participants accepted the £40 offer 35% more often than the 25£ offer and 72% more often than the £10 offer: 
$\chi^2(2)$ = 102.57, p < .001
      
Means and standard deviations for each offer can be viewed in the table below. 
Offer 1 is the £10 offer, 2 is £25 and 3 is £40. 



```{r cell_means,  }

knitr::kable(ultim_summary)

```

Moreover, the analysis revealed a significant main effect of the source (stim_type).
As expected, unfair offers (£10) from the computer were accepted on average more often as compared to the same offers proposed by brands and humans : $\chi^2(2)$ = 15.761, p < .001

However, testing the interaction between offer type and proposer did not yielded significant results,  $\chi^2(4)$ = 8.55, p = .073. 
This is attributable to the fact that the main effect of the source was observable only on one level of the offer type, namely the £10 offer (offer1). This is easily visualised in the bar chart below. 

```{r bar_chart }

print(col_plot)
 
```

################################################
Code for the ANOVA, with the same variables 

```{r analysis - anova }

anova.mean <- aggregate(ultimatum$acceptance,
                      by = list(ultimatum$subj_id, ultimatum$stim_type,
                              ultimatum$offer),
                      FUN = 'mean')

ggplot(anova.mean, aes(x=offer, y=acceptance)) + geom_jitter() + facet_grid(~stim_type)
ggplot(anova.mean, aes(x=stim_type, y=acceptance)) + geom_col() + facet_grid(~offer)

colnames(anova.mean) <- c("Subj_id","stim_type","offer","acceptance")

anova.mean <- anova.mean[order(anova.mean$Subj_id), ]

anova.mean$Subj_id <- as.factor(anova.mean$Subj_id)
anova.mean$stim_type <- as.factor(anova.mean$stim_type)
anova.mean$offer <- as.factor(anova.mean$offer)


ultimatum.anova <- aov(acceptance ~ offer * stim_type +
                       Error(Subj_id / (offer * stim_type)), data = anova.mean)

summary(ultimatum.anova)

install.packages("lsmeans")
library(lsmeans)

 ### offer 
lsmeans(ultimatum.anova, list(pairwise ~ offer), adjust = "tukey")



## stim_type 
lsmeans(ultimatum.anova, list(pairwise ~ stim_type), adjust = "tukey")
TukeyHSD(ultimatum.anova, "stim_type")
#### pairwaise t test for offer 
posthoc <- TukeyHSD(ultimatum.anova, "offer", conf.level=0.95)
pairwise.t.test(anova.mean$acceptance, anova.mean$offer, p.adj = "none")

## post hoc pairwise test for stim_type 
pairwise.t.test(anova.mean$acceptance, anova.mean$stim_type, p.adj = "none")


```



**Ratings of Trustworthiness**

Working with the ratings of trustworthiness. Below, I created a dataframe with the trustworthiness ratings only. Ratings of trustworthiness are grouped into categories:

  - rating1 = [0,10,20,30]
  - rating2 = [4,50,60]
  - rating3 = [70,80,90,100]


```{r trust, warning= FALSE}
### recoding of variabels, binning the trustworthiness ratings into 3 categories. 
0
trust <- final_data %>%
  group_by(subj_id) %>%
    filter(game == "trust") %>%
   mutate(rating_binned = ifelse(response <=4, 1,
          ifelse(response %in% 5:7, 2,
                 ifelse(response >= 8, 3, 0)))) %>%
        mutate(rating1 = ifelse(response <= 4, .5, -.5 ),
            rating2 = ifelse(response == 7 | response == 6| response ==5, .5, -.5), rating3 = ifelse(response >= 8, .5,-.5))


```


Now I created a merged data_frame including ratings of trustworthiness and ultimatum responses. 
In order to analyse the effect of brand and human only and account for the ratings of trustworthiness, the ultimatum game responses relative to computer offers were dropped from the following computations. 

```{r preprocessing_trust, warning= FALSE}

ultimatum_no_computer <- ultimatum %>%
  filter(stim_type != "computer") %>%
  dplyr::select(stim_type, stim1, subj_id, acceptance, offer)

rating <- trust %>%
  group_by(stim1) %>%
dplyr::select(rating_binned, subj_id, stim1, stim_type)

rating_mod <- trust %>%
  group_by(stim1) %>%
  dplyr::select(rating_binned, rating1, rating2, rating3, stim1, subj_id, stim_type)

joined_mod <- merge(rating_mod, ultimatum_no_computer)

###########################################

anova <- merge(rating, ultimatum_no_computer)

anova.mean2 <- aggregate(anova$acceptance,
                      by = list(anova$subj_id, anova$stim_type,
                              anova$offer, anova$rating_binned),
                      FUN = 'mean')


colnames(anova.mean2) <- c("Subj_id","stim_type","offer","rating", "acceptance")

anova.mean2 <- anova.mean2[order(anova.mean2$Subj_id), ]

anova.mean2$Subj_id <- as.factor(anova.mean2$Subj_id)
anova.mean2$stim_type <- as.factor(anova.mean2$stim_type)
anova.mean2$offer <- as.factor(anova.mean2$offer)
anova.mean2$rating <- as.factor(anova.mean2$rating)

rating.anova <- aov(acceptance ~ offer * stim_type * rating +
                       Error(Subj_id / (offer * stim_type)), data = anova.mean2)

summary(rating.anova)

lsmeans(rating.anova, list(pairwise ~ rating), adjust = "tukey")

ratings_model <- joined_mod %>%
  mutate(offer_1 = ifelse(offer == "3", .5, -.5),
    offer_3 = ifelse(offer == "2", .5, -.5),  
      brand = ifelse(stim_type == "brand", .5, -.5)) %>%
          dplyr::select(subj_id, offer_1, offer_3, brand, rating1, rating2, rating3, acceptance,stim1)

joined <- merge(rating, ultimatum_no_computer)



join_summary$rating_binned <- as.factor(join_summary$rating_binned)

ggplot(join_summary, aes(x=rating_binned, y=p, fill = stim_type)) + geom_col(colour = "black", alpha = 0.7, position = "dodge") + 
  facet_grid(~offer, labeller = as_labeller(offer_types)) +
  labs(fill = "Proposer Type", x = NULL, y = "Proportion of Accepted Offers", 
       title = "Distribution of Accepted Offers by Offer Type and Proposer Type", 
       subtitle = "Offer Amount", caption = "Data from the Ultimatum Game") +
  scale_y_continuous(labels = percent) + theme_bw()



join2 <- joined %>%
  group_by(rating_binned, stim_type) %>%
    summarise(p = mean(acceptance),
              sd = sd(acceptance)) 




plot2 <- ggplot(join2, aes(rating_binned, p, colour=stim_type)) + 
        geom_line() +   geom_point() +   coord_cartesian(ylim = c(0, 1)) +
           labs(y = "probability") + labs(colour = "Proposer Type" , x = "Rating Categories", y = "Proportion of Accepted Offers", title = "Proportion of Accepted Offers by Proposer Type  and \nTrustworthiness Ratings Categories") + scale_y_continuous(labels = percent) + scale_x_continuous(breaks = c(1,2,3), labels = c("Category 1","Category 2","Category 3"))

print(plot2)

```

From the graph above it is possible to notice that at equal ratings of trustworthiness, participants accepted offers from brands and humans in a slight yet dissimilar way. 
Specifically, higher ratings of trustworthiness seemed to affect only acceptance of brands offer, which slightly increased. 

In order to visualise the relationship in a more detailed manner, I added the different offer to the plot. 

```{r trust_plot, warning= FALSE}


join_summary <- joined %>%
  dplyr::group_by(subj_id, rating_binned, stim_type) %>%
    dplyr::summarise(p = mean(acceptance))



ggplot(join_summary, aes(x = stim_type, y= p, fill=stim_type)) + 
        geom_boxplot(colour = "black", alpha = 0.7) +   coord_cartesian(ylim = c(0, 1), xlim = c(1,2,3)) + facet_grid(~rating_binned) + labs(fill = "Proposer Type", x = NULL, y = "Proportion of Accepted Offers", title = "Proportion of Accepted Offers by Offer Type and Proposer Type \nat Different Rating Categories", subtitle = "Rating of Trustworthiness", caption = "Data from the Ultimatum Game") + scale_y_continuous(labels = percent) + theme_bw()




```

Althought no clear pattern or relationship seem to emerge from the graph, it is still noticeable that perceived trust has a bigger effect on acceptance of offers from brands as compared to offers from humans. 

As the table and bar chart below show, differences in acceptance rates between brands and human offers were higher in the highest rating categories (rating3) and showed a preference to accept offers proposed by brands. 

```{r descriptive_trust}
knitr::kable(join2)

plot_join <- ggplot(join2, aes(x = stim_type, y = p, fill = stim_type)) + geom_col() +
  facet_grid(~rating_binned) 

print(plot_join)

```


**ANALYSIS ** 

Acceptance rates were analysed with a logistic mixed effects model in which offer type (£10 or 25£), rating category (binned into 3 categories as specified above) and source (brand or human) were coded as predictors. 
In order to account for the repeated measures design and allow generalization of results, subjects and items (stimuli, coded as stim1) were introduced as random factors. 

```{r analysis_mixed model, results="hide"}

########## mixed model

rat_model <- glmer(acceptance ~ (offer_1 + offer_3) * brand  * (rating2 + rating3) + ( (offer_1 + offer_3) * (brand )||subj_id) + (1|stim1), ratings_model, binomial, control=glmerControl(optimizer="bobyqa", optCtrl= list(maxfun=100000)))

summary(rat_model)

View(ratings_model)

model_trust <- glmer(acceptance ~ offer * stim_type * rating_binned  + (offer * stim_type ||subj_id) + (rating_binned || stim1), joined_mod, binomial, control=glmerControl(optimizer="bobyqa", optCtrl= list(maxfun=100000)))

summary(model_trust)

mod_trust2 <- update(model_trust, . ~ . -offer1)
anova(model_trust, mod_trust2) # test main effect of first factor

mod_trust3 <- update(model_trust, . ~ . -stim_type_b)
anova(model_trust, mod_trust3) # test main effect of second factor

mod_trust4 <- update(model_trust, .~ . -rating1 -rating3)
anova(model_trust, mod_trust4) ## test main effect of third factor 

mod_trust_inter <- update(model_trust, . ~ . -offer1:stim_type_b - offer1:rating1 - offer1:rating3 - stim_type_b:rating1 - stim_type_b:rating3)
anova(model_trust, mod_trust_inter) # test interaction


mod_new <- glmer(acceptance ~ (rating1 + rating3) * stim_type_b + (stim_type_b || subj_id), rat_mod_2, binomial, control=glmerControl(optimizer="bobyqa", optCtrl= list(maxfun=100000)))

summary(mod_new)

```

**Interpretation**

There was no main effect of source, $\chi^2(1)$ = 2.54, p = .110. 
As predicted from the graph, there was however a main effect of rating of trustworthiness, $\chi^2(2)$ = 12.031, p < .001, meaning that differences in ratings predicted differences in acceptance rates. Specifically, higher ratings were associated with increased acceptance. 

Analysis of the interaction between ratings of trustworthiness and source type were non significant, suggesting that at equal ratings predict similar patterns of acceptance for both human and brands offer. 


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


SECOND PART, **REACTION TIMES**.

I created a data_frame and summarised the reaction times grouping by subjects, stimulus type and kind of offer. 

```{r reaction times}

ultimatum$acceptance <- as.numeric(ultimatum$acceptance)
ultimatum$RT <- as.numeric(ultimatum$RT)
ultimatum$subj_id <- as.character(ultimatum$subj_id)
ultimatum$stim1 <- as.factor(ultimatum$stim1)
ultimatum$offer <- as.factor(ultimatum$offer)
ultimatum$stim_type <- as.factor(ultimatum$stim_type)

library(plyr)

ultim_RT <- ultimatum %>%
  group_by(subj_id, stim_type, offer, stim1) %>%
    dplyr::summarise(mean_rt = mean(RT))

se_rt <- ddply(ultimatum, c("stim_type", "offer", "subj_id"), summarise,
      mean = mean(RT), sd = sd(RT),
      se = sd(RT)/sqrt(length(RT)))

violinplot <- ggplot(ultim_RT, aes(offer, mean_rt)) + geom_violin()
print(violinplot)

ug <- ggplot(se_rt, aes(offer, mean, fill = offer)) + geom_col() + facet_grid(~stim_type) + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1)

print(ug)



col_plot_rt <- ggplot(ultim_RT, aes(x = offer, y = mean_rt, fill = offer)) + geom_col() + facet_grid(~stim_type)
print(col_plot_rt)

hist <- hist(ultim_RT$mean_rt, breaks = 30, main = "distribution with outliers")

```

The distribution of the mean reaction times is visualised with a violin_plot split by offer type, while overall distribution is presented in the histogram below. 
It is possible to notice the presence of outliers which will be removed before continuing with the analysis. 


```{r outliers, results="hide"}

outliers <- ggplot(ultim_RT, aes(offer, mean_rt)) + geom_boxplot() + ggtitle("Mean Reaction Times With Outliers")

print(outliers)

rem_outlier_rt <- ultim_RT %>%
  filter(mean_rt < 3000, mean_rt>500) 

rem_outliers <- ggplot(rem_outlier_rt, aes(offer, mean_rt)) + geom_boxplot() + ggtitle("Mean Reaction Times Without Outliers")

a <- ggplot(rem_outlier_rt, aes(offer, mean_rt, fill = offer)) + geom_boxplot(colour = "black") + ggtitle("Mean Reaction Times Without Outliers") + labs(y = "Mean Reaction Times to UG Offers") + facet_grid(~stim_type)

print(a)
print(rem_outliers)


out <-ddply(ultimatum, c("stim_type", "offer"), summarise,
      mean = mean(RT), sd = sd(RT),
      se = sd(RT)/sqrt(length(RT)))

out_plot <- ggplot(out, aes(x = offer, y = mean, fill = offer)) + geom_col() + facet_grid(~stim_type) + labs(fill = "Offer Types", x = "Amount Offered", y = "Mean Reaction Times", title = "Mean Reaction Times by Offer Type and Proposer Type", caption = "Data from the Ultimatum Game") + scale_x_discrete(breaks = c(1,2,3), labels = c("£10", "£25","£40")) + geom_errorbar(aes(ymin=mean-se, ymax=mean+se))

print(out_plot)


col_plot_no_out <- ggplot(se_rt, aes(x = offer, y = mean, fill = offer)) + geom_col() + facet_grid(~stim_type) + labs(fill = "Offer Types", x = "Amount Offered", y = "Mean Reaction Times", title = "Mean Reaction Times by Offer Type and Proposer Type", caption = "Data from the Ultimatum Game") + scale_x_discrete(breaks = c(1,2,3), labels = c("£10", "£25","£40")) + geom_errorbar(aes(ymin=mean-se, ymax=mean+se))

print(col_plot_no_out)
```


The distribution without the outliers is presented in the figures below and looks closer to a normal distribution. 

```{r print_no_outliers}

hist_no_out <- hist(rem_outlier_rt$mean_rt, breaks = 30, main ="distribution without outliers")

violinplot_no_out <- ggplot(rem_outlier_rt, aes(offer, mean_rt)) + geom_violin()
print(violinplot_no_out)

```

Descriptive statistics are provided in the table below and presented in the bar chart. 

```{r plots}

rem_outlier_rt$offer <- as.factor(rem_outlier_rt$offer)

plot_rt <- rem_outlier_rt %>%
  group_by(offer, stim_type, subj_id) %>%
  dplyr::summarise(mean = mean(mean_rt),
         SD = sd(mean_rt, na.rm = TRUE)) 

plot__ <- ggplot(plot_rt, aes(x = offer, y = mean, fill = offer)) + geom_col() + facet_grid(~stim_type)

print(plot__)
  
```



The bar plot shows that intensity of the offer (highest fairness and highess unfairness (offer 1 and 3) are associated as expected with shorter reaction times as compared to the highest uncertainty condition simulated with offer2 (25/75 split). 
This relationship was analysed with a repeated measures analysis of variance 


```{r mixed_model_rt, warning=FALSE,results="hide"}

#### recoding 

ultim_RT_recode <- rem_outlier_rt %>% 
    mutate(offer_1 = ifelse(offer == "1", .5, -.5),
    offer_3 = ifelse(offer == "3", .5, -.5),
      brand = ifelse(stim_type == "brand", .5, -.5),
        human = ifelse(stim_type == "human", .5, -5))
  
## mixed model formula 

mod_rt2 <- lmer(mean_rt ~ (offer_1 + offer_3) + ((offer_1 + offer_3)|| subj_id), ultim_RT_recode)

summary(mod_rt2)


mod_rt <- lmer(mean_rt ~ (offer_1 + offer_3) * (brand + human) + ( (offer_1 + offer_3) * (brand + human)||subj_id), ultim_RT_recode)

summary(mod_rt)

anova(mod_rt, mod_rt2)
 ##likelihood ratio tests 

rt_offer_mod <- update(mod_rt, . ~ . -offer_1 -offer_3)
anova(mod_rt, rt_offer_mod) # test main effect of first factor

rt_stim_mod <- update(mod_rt, . ~ . -brand - human)
anova(mod_rt, rt_stim_mod) # test main effect of second factor

rt_interaction_mod <- update(mod_rt, . ~ . -offer_1:brand - offer_1:human - offer_2:brand - offer_2:human)
anova(mod_rt, rt_interaction_mod) # test interaction





```


The analysis showed a main effect of offer, such that offer1 and offer2 significantly differed in the acceptance reaction times as compared to offer3, set as baseline measure. 
Specifically, offers in the most uncertain condition (£25) were accepted slower than offers in the other categories. 

However, no significant interaction was found between the factors. 

```{r anova_rt}

options(contrasts = c("contr.sum","contr.poly"))

mod_rt <- aov(mean_rt ~ stim_type*offer + Error(subj_id), ultim_RT_recode)
summary(mod_rt)
```

The anova yielded results similar to the mixed models regression by finding a main effect of source type and offer, and no effect of the interaction of the factors. 



