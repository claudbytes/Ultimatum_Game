---
title: "L4 Advanced Stats Homework 4"
author: "University of Glasgow, School of Psychology"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Instructions

Leave everything above this section in the file.

Save this file in your working directory as an .Rmd file. Ensure you save it in the same location where you put the .csv files you will use for this assignment.  

You should then set your working directory for the console to point to this same location (from the pulldown menu, select Session | Set Working Directory...). 

*NOTE*: in all of the problems below, you will need to replace `NULL` with a value or some code that computes a value, vector, or table.  Feel free to add any additional code you think you might need inside these blocks.  When altering code inside the code blocks, please *do not* re-order or rename the code blocks (T1, T2, ... etc.).  Also, **do not rename any code blocks or the variable names you are given within the code blocks!**  If you do, this will impact your grade!  If you have changed these things and complain to us that this affected your grade despite the code being correct, *we will send you back to re-read this paragraph*.

**Strive to make your report reproducible.**  This means: define all values using code, rather than typing in a number, such that if the underlying data were to change, it would still give you a correct (but possibly different result).

It's also recommended that you "Knit" a report to be able to see what you've accomplished and spot potential errors.  Make sure the file compiles to HTML *without errors* before you submit.  **BUT DO NOT SUBMIT THE HTML version**: submit the RMarkdown (.Rmd) script with your answers, using the link provided on the Moodle page.  

Some resources that you may find helpful in completing the assignment:

- [RStudio IDE cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/rstudio-ide.pdf)
- [RStudio data import cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf)
- [RStudio data transformation cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf)
- [RStudio data visualization cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-visualization-2.1.pdf)
- [RMarkdown Reference Guide](https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf)

Also remember that you can get help for any function `?pkgname::function_name` in the console.  For example to get help on `read_csv()` in `dplyr`, you would type `?dplyr::read_csv`.  If `dplyr` is already loaded (e.g., because you have loaded the `tidyverse` package), then you would only need to type `?read_csv`.  (But don't put any of your attempts to use the help system in your RMarkdown file!)

----

# Data pre-processing and visualisation

Your task for this assignment is to use linear mixed-effects models to re-analyze data from Experiment 2 of Keysar, Barr, Balin, and Brauner (2000). The data can be found in an online github repository:
<https://github.com/dalejbarr/kbbb2000>.

Read the paper before you start:

Keysar, B., Barr, D. J., Balin, J. A., Brauner, J. S. (2000). Taking perspective in conversation: The role of mutual knowledge in comprehension. Psychological Science, 11, 32-38.

**Also, the github site contains further information about the experiment and the dataset. Be sure to read this too.**

## Task 1

Load in the libraries and data you need.  *Do not change the variable names that have been provided.*

```{r T1, message = FALSE}
library("lme4")
library("tidyverse")

subjects <- read_csv("exp2_subjects.csv")

trials <- read_csv("exp2_trials.csv")
```


## Task 2

The two main IVs you will test are: `psource`  and `cond`. The random factors are *subjects* and *stimulus items*, identified in the data by the variables `subj` and `object` respectively.  You will fit models for each of three DVs: `firstfix`, `rt`, and `totfix`.

Describe the design of the experiment, in terms of whether each factor is within subjects or between subjects, and within items or between items.

**Replace NULL with TRUE or FALSE for subjects and items.  Type TRUE or FALSE; do *not* put the words TRUE or FALSE in quotations.**

```{r T2}
# within/between subjects:
is_psource_within_subjects <- FALSE
is_cond_within_subjects <- TRUE 

# within/between items:
is_psource_within_items <- TRUE
is_cond_within_items <- TRUE
```

## Task 3

Create a single dataset `dat` that includes *only* the following columns: `subj`, `object`, the two IVs, and the three DVs.

```{r T3}
dat <- inner_join(subjects, trials, "subj") %>%
  select(subj, object, psource, cond, firstfix, rt, totfix)
```

## Task 4

Visualise the relationships between your IVs and the condition means of your DVs in some sensible way (do *not* use a bar plot).  Use meaningful labels that a reader could understand.  Create your plot using ggplot2 functions.

```{r T4}
nice_DV_names <- tibble(var = c("firstfix", "rt", "totfix"),
                     vname = c("First fixation on target",
                               "Response time",
                               "Total time on critical"))

nice_cond <- tibble(cond = c("C", "E"),
                    cname = c("noncomp", "comp"))

nice_psource <- tibble(psource = c("EX", "RN"),
                       pname = c("experimenter", "lottery"))

nice_dat <- dat %>%
  gather("var", "value", firstfix, rt, totfix) %>%
  inner_join(nice_DV_names, "var") %>%
  inner_join(nice_cond, "cond") %>%
  inner_join(nice_psource, "psource") 

nd_means <- nice_dat %>% 
  group_by(vname, pname, cname) %>%
  summarise(v = mean(value, na.rm = TRUE))

nd_means %>%
  ggplot(aes(cname, v)) +
  geom_line(aes(group = pname)) +
  geom_point(aes(shape = pname), size = 3) +
  facet_wrap(~vname, scales = "free_y") +
  labs(shape = "information source", x = "critical object")
```


# Fitting models

For these next few tasks, you will fit linear-mixed effects models that estimate the effects of the two IVs (`psource` and `cond`) on the three DVs in the experiment: `firstfix`, `rt`, and `totfix`. Your models should include subjects and items as crossed random factors, and should have the maximal random effects justified by the design. Use deviation coding for the predictors. (See <http://talklab.psy.gla.ac.uk/tvw/catpred> for information on different coding schemes.) Test for the main effects of each IV and the interaction using likelihood ratio tests (e.g., using the anova() function to compare models, as described in class). Fit each model with the option `REML = FALSE`.

If you have trouble getting the maximal model to converge, try setting the covariance parameters to zero by using the double bar instead of the single bar syntax. For instance:

*single-bar syntax: lmer(Y ~ A + (A | Subject)...)  
*double-bar syntax: lmer(Y ~ A + (A || Subject)...)  

With the double-bar syntax, you estimate only the variance parameters but not the covariances (the correlations between the random effects). This simplifies the random effects structure, and simulations suggest that it doesn't impact the inferential performance of the model too badly.

## Task 5

Create two new deviation-coded predictor variables in `dat` for `psource` and `cond`, named `ps` and `cd` respectively, to match the requirements in the table below.  Store the resulting table in `dat2`.

| `psource` | `ps` |
|-----------|------|
| `EX`      | -.5  |
| `RN`      |  .5  |

| `cond` | `ps` |
|--------|------|
| `E`    |  .5  |
| `C`    |  -.5  |


```{r T5}
dat2 <- dat %>%
  mutate(ps = ifelse(psource == "EX", -.5, .5),
         cd = ifelse(cond == "E", .5, -.5))
```

## Task 6

Fit a model of the effects of `ps`, `cd`, and their interaction on `firstfix`, with the maximal random effects structure justified by the design.  Use `summary()` to print out the model statistics.

```{r T6}
mod_ff <- lmer(firstfix ~ ps * cd + (cd | subj) + (ps * cd | object),
               dat2, REML = FALSE)

summary(mod_ff)
```

## Task 7

Now fit three additional models.

1. `mod_ff_cd`, identical to `mod_ff` except `cd` is dropped;
2. `mod_ff_ps`, identical to `mod_ff` except `ps` is dropped;
3. `mod_ff_ix`, identical to `mod_ff` except the `cd` by `ps` interaction is dropped.

```{r T7}
mod_ff_cd <- update(mod_ff, . ~ . -cd)
mod_ff_ps <- update(mod_ff, . ~ . -ps)
mod_ff_ix <- update(mod_ff, . ~ . -ps:cd)
```

## Task 8

Now use likelihood ratio tests to compare:

1. `mod_ff` to `mod_ff_cd`;
2. `mod_ff` to `mod_ff_ps`;
3. `mod_ff` to `mod_ff_ix`.

```{r T8}
av_ff_cd <- anova(mod_ff, mod_ff_cd)
av_ff_ps <- anova(mod_ff, mod_ff_ps)
av_ff_ix <- anova(mod_ff, mod_ff_ix)
```

## Task 9

Report your results for the analysis of first fixation in a paragraph.  Use APA format, and generate your statistical values using inline code so that if the underlying data were to change, the reported values would change.  Use the code block below (which is omitted from the report using `echo=FALSE`) to extract values to be used in your report.

```{r extra_block, echo=TRUE}
## get marginal means and cell means
mmeans_cond <- dat2 %>% # marginal means
  group_by(cond) %>%
  summarise(m = mean(firstfix, na.rm = TRUE),
            s = sd(firstfix, na.rm = TRUE)) %>%
  arrange(desc(cond)) %>%
  ungroup()

diff_cond <- mmeans_cond %>% 
  pull(m) %>% reduce(`-`) %>% round()

mmeans_psource <- dat2 %>%
  group_by(psource) %>%
  summarise(m = mean(firstfix, na.rm = TRUE),
            s = sd(firstfix, na.rm = TRUE)) %>%
  arrange(psource) %>%
  ungroup()

diff_psource = mmeans_psource %>%
  pull(m) %>% reduce(`-`) %>% round

cell_means <- dat2 %>%
  group_by(psource, cond) %>%
  summarise(mean = mean(firstfix, na.rm = TRUE) %>% round(), 
            sd = sd(firstfix, na.rm = TRUE) %>% round()) %>%
  ungroup() %>%
  mutate(Source = recode(psource, "EX"= "Experimenter",
                         "RN" = "Lottery"),
         `Critical object` = recode(cond, "E" = "Competitor",
                                    "C" = "Noncompetitor"))

cond_x2 <- av_ff_cd %>% pull(Chisq) %>% pluck(2) %>% round(2)
psource_x2 <- av_ff_ps %>% pull(Chisq) %>% pluck(2) %>% round(2)
ix_x2 <- av_ff_ix %>% pull(Chisq) %>% pluck(2) %>% round(2)

cond_p <- av_ff_cd %>% pull(`Pr(>Chisq)`) %>% pluck(2) %>% round(3)
psource_p <- av_ff_ps %>% pull(`Pr(>Chisq)`) %>% pluck(2) %>% round(3)
ix_p <- av_ff_ix %>% pull(`Pr(>Chisq)`) %>% pluck(2) %>% round(3)


## THIS BLOCK IS NOT ASSESSED
## use it to compute any single values you need
cell_means %>% select(Source, `Critical object`, mean, sd) %>%
  knitr::kable()
```

****

There was a main effect of Critical object such that participants fixated the target `r diff_cond` ms later in when the critical object was a competitor, $\chi^2(1)$ = `r cond_x2`, $p$ = `r cond_p`.  The means (and standard deviations) were `r mmeans_cond %>% pull(m) %>% pluck(1) %>% round()` (SD = `r mmeans_cond %>% pull(s) %>% pluck(1) %>% round()`) for competitors and `r mmeans_cond %>% pull(m) %>% pluck(2) %>% round()` (SD = `r mmeans_cond %>% pull(s) %>% pluck(2) %>% round()`) for noncompetitors.

There was no main effect of Information Source, $\chi^2(1)$ = `r psource_x2`, $p$ = `r psource_p`.  The means (and standard deviations) were `r mmeans_psource %>% pull(m) %>% pluck(1) %>% round()` (SD = `r mmeans_psource %>% pull(s) %>% pluck(1) %>% round()`) for the experimenter condition and `r mmeans_psource %>% pull(m) %>% pluck(2) %>% round()` (SD = `r mmeans_psource %>% pull(s) %>% pluck(2) %>% round()`) for the lottery condition.

Most importantly, there was no evidence for any interaction between information source and competitor, $\chi^2(1)$ = `r ix_x2`, $p$ = `r ix_p`.  Please see Table X above for cell means and standard deviations.

****

# Extra challenge (optional)

Repeat the analysis on the two additional DVs: `totfix` and `rt` (add additional code blocks as needed).
